{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from scipy.stats import uniform\n",
    "import pandas as pd # Para cargar los datos y hacer OHE.\n",
    "import numpy as np  # Para lidiar con NaNs.\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the competition data\n",
    "comp_data = pd.read_csv(\"../competition_data.csv\")\n",
    "\n",
    "#aher OHE con pdp\n",
    "comp_data['is_pdp'].fillna(-1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comp_data = pd.get_dummies(comp_data, columns=['is_pdp'], prefix='is_pdp')\n",
    "\n",
    "comp_data = pd.get_dummies(comp_data, columns=['listing_type_id','logistic_type','platform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = comp_data.drop(\n",
    "    columns=['accepts_mercadopago',\n",
    "            # 'available_quantity',\n",
    "            # 'avg_gmv_item_domain_30days',\n",
    "            # 'avg_gmv_item_sel',\n",
    "            # 'avg_gmv_seller_bday',\n",
    "            # 'avg_qty_orders_item_domain_30days',\n",
    "            # 'avg_qty_orders_item_sel_30days',\n",
    "            # 'avg_si_item_sel_30day',\n",
    "            'benefit',\n",
    "            'boosted',\n",
    "            'category_id',\n",
    "            # 'conversion',\n",
    "            'date',             #chiche d efechas separar dia mes etc\n",
    "            'deal_print_id',\n",
    "            'domain_id',\n",
    "            'etl_version',\n",
    "            'free_shipping',    \n",
    "            'fulfillment',\n",
    "            'full_name',\n",
    "            # 'health',\n",
    "            # 'is_pdp',\n",
    "            'product_id',\n",
    "            'item_id',\n",
    "            # 'listing_type_id', #hacer OHE\n",
    "            # 'logistic_type',   #hacer OHE\n",
    "            'main_picture',\n",
    "            # 'offset',\n",
    "            # 'original_price',\n",
    "            # 'platform',        #hacer OHE\n",
    "            # 'price',\n",
    "            # 'print_position',\n",
    "            'print_server_timestamp',\n",
    "            # 'qty_items_dom',\n",
    "            # 'qty_items_sel',\n",
    "            'site_id',\n",
    "            # 'sold_quantity',\n",
    "            'tags',             #experimentar\n",
    "            'title',            #W2vec\n",
    "            # 'total_asp_item_domain_30days',\n",
    "            # 'total_asp_item_sel_30days',\n",
    "            # 'total_gmv_domain_bday',\n",
    "            # 'total_gmv_item_30days',\n",
    "            # 'total_items_domain',\n",
    "            # 'total_items_seller',\n",
    "            # 'total_orders_domain_30days',\n",
    "            # 'total_orders_item_30days',\n",
    "            # 'total_orders_sel_30days',\n",
    "            # 'total_si_domain_30days',\n",
    "            # 'total_si_item_30days',\n",
    "            # 'total_si_sel_30days',\n",
    "            # 'total_visits_domain',\n",
    "            # 'total_visits_item',\n",
    "            # 'total_visits_seller',\n",
    "            'uid',\n",
    "            'user_id',\n",
    "            'warranty',\n",
    "            # 'ROW_ID'\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and evaluation samples\n",
    "train_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "del comp_data\n",
    "gc.collect()\n",
    "\n",
    "y_train_all = train_data[\"conversion\"]\n",
    "X_train_all = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "# X_train_all = X_train_all.select_dtypes(include='number') \n",
    "del train_data\n",
    "gc.collect()\n",
    "\n",
    "#hold out set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "available_quantity                     int64\n",
       "avg_gmv_item_domain_30days           float64\n",
       "avg_gmv_item_sel                     float64\n",
       "avg_gmv_seller_bday                  float64\n",
       "avg_qty_orders_item_domain_30days    float64\n",
       "avg_qty_orders_item_sel_30days       float64\n",
       "avg_si_item_sel_30day                float64\n",
       "health                               float64\n",
       "offset                                 int64\n",
       "original_price                         int64\n",
       "price                                  int64\n",
       "print_position                         int64\n",
       "qty_items_dom                        float64\n",
       "qty_items_sel                        float64\n",
       "sold_quantity                          int64\n",
       "total_asp_item_domain_30days         float64\n",
       "total_asp_item_sel_30days            float64\n",
       "total_gmv_domain_bday                float64\n",
       "total_gmv_item_30days                float64\n",
       "total_items_domain                     int64\n",
       "total_items_seller                     int64\n",
       "total_orders_domain_30days           float64\n",
       "total_orders_item_30days             float64\n",
       "total_orders_sel_30days              float64\n",
       "total_si_domain_30days               float64\n",
       "total_si_item_30days                 float64\n",
       "total_si_sel_30days                  float64\n",
       "total_visits_domain                    int64\n",
       "total_visits_item                      int64\n",
       "total_visits_seller                    int64\n",
       "is_pdp_-1                               bool\n",
       "is_pdp_False                            bool\n",
       "is_pdp_True                             bool\n",
       "listing_type_id_gold_pro                bool\n",
       "listing_type_id_gold_special            bool\n",
       "logistic_type_cross_docking             bool\n",
       "logistic_type_custom                    bool\n",
       "logistic_type_default                   bool\n",
       "logistic_type_drop_off                  bool\n",
       "logistic_type_fulfillment               bool\n",
       "logistic_type_not_specified             bool\n",
       "logistic_type_xd_drop_off               bool\n",
       "platform_/mobile/android                bool\n",
       "platform_/mobile/ios                    bool\n",
       "platform_/web/desktop                   bool\n",
       "platform_/web/mobile                    bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can not initialize DMatrix from DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_base.py:371\u001b[0m, in \u001b[0;36m_spbase.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 371\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method(copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    372\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_coo.py:412\u001b[0m, in \u001b[0;36m_coo_base.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    411\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(col, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m--> 412\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, dtype\u001b[39m=\u001b[39mupcast(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n\u001b[0;32m    414\u001b[0m coo_tocsr(M, N, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz, row, col, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[0;32m    415\u001b[0m           indptr, indices, data)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_sputils.py:53\u001b[0m, in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m---> 53\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mno supported conversion for types: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:481\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m     csr \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mcsr_matrix(data)\n\u001b[0;32m    482\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_csr(csr)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:83\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munrecognized \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_matrix constructor usage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m(\n\u001b[0;32m     84\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coo_container(arg1, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m     85\u001b[0m     ))\n\u001b[0;32m     87\u001b[0m \u001b[39m# Read matrix dimensions given, if any\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:32\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     arg1 \u001b[39m=\u001b[39m arg1\u001b[39m.\u001b[39;49masformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat)\n\u001b[0;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(arg1)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_base.py:373\u001b[0m, in \u001b[0;36m_spbase.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_coo.py:412\u001b[0m, in \u001b[0;36m_coo_base.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    411\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(col, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m--> 412\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, dtype\u001b[39m=\u001b[39mupcast(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n\u001b[0;32m    414\u001b[0m coo_tocsr(M, N, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz, row, col, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[0;32m    415\u001b[0m           indptr, indices, data)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_sputils.py:53\u001b[0m, in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m---> 53\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mno supported conversion for types: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lucas\\OneDrive\\Documentos\\td6\\tp2_td6\\modelos viejos\\limpio.ipynb Celda 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/OneDrive/Documentos/td6/tp2_td6/modelos%20viejos/limpio.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m ParameterSampler(params, n_iter \u001b[39m=\u001b[39m iterations, random_state \u001b[39m=\u001b[39m random_state):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/OneDrive/Documentos/td6/tp2_td6/modelos%20viejos/limpio.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     clf_xgb \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(objective \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m, seed \u001b[39m=\u001b[39m random_state, eval_metric \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mg) \u001b[39m#enable_categorical = True\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lucas/OneDrive/Documentos/td6/tp2_td6/modelos%20viejos/limpio.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     clf_xgb\u001b[39m.\u001b[39;49mfit(X_train, y_train, eval_set \u001b[39m=\u001b[39;49m [(X_val, y_val)], verbose \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/OneDrive/Documentos/td6/tp2_td6/modelos%20viejos/limpio.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m clf_xgb\u001b[39m.\u001b[39mpredict_proba(X_val)[:, \u001b[39m1\u001b[39m] \u001b[39m# Obtenemos la probabilidad de una de las clases (cualquiera).\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/OneDrive/Documentos/td6/tp2_td6/modelos%20viejos/limpio.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     auc_roc \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mroc_auc_score(y_val, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:794\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[39mif\u001b[39;00m sample_weight_eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     sample_weight_eval_set \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m--> 794\u001b[0m evals \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m    795\u001b[0m     DMatrix(eval_set[i][\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    796\u001b[0m             label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_le\u001b[39m.\u001b[39;49mtransform(eval_set[i][\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m    797\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing, weight\u001b[39m=\u001b[39;49msample_weight_eval_set[i],\n\u001b[0;32m    798\u001b[0m             nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n\u001b[0;32m    799\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(eval_set))\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m nevals \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(evals)\n\u001b[0;32m    802\u001b[0m eval_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvalidation_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nevals)]\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:795\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[39mif\u001b[39;00m sample_weight_eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     sample_weight_eval_set \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[0;32m    794\u001b[0m evals \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m--> 795\u001b[0m     DMatrix(eval_set[i][\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    796\u001b[0m             label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_le\u001b[39m.\u001b[39;49mtransform(eval_set[i][\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m    797\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing, weight\u001b[39m=\u001b[39;49msample_weight_eval_set[i],\n\u001b[0;32m    798\u001b[0m             nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n\u001b[0;32m    799\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(eval_set))\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m nevals \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(evals)\n\u001b[0;32m    802\u001b[0m eval_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvalidation_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nevals)]\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:484\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_csr(csr)\n\u001b[0;32m    483\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcan not initialize DMatrix from\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    485\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(data)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[0;32m    487\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_label(label)\n",
      "\u001b[1;31mTypeError\u001b[0m: can not initialize DMatrix from DataFrame"
     ]
    }
   ],
   "source": [
    "#ver uan forma de tener mejor parametos que gerar\n",
    "params = {'max_depth': list(range(3, 12)),\n",
    "          'learning_rate': uniform(scale = 0.03),\n",
    "          'gamma': uniform(scale=15),               #chiche va de 1 a 20\n",
    "          'reg_lambda': uniform(scale = 15),        # Parámetro de regularización.\n",
    "          'subsample': uniform(0.5, 0.5),          # Entre 0.5 y 1.\n",
    "          'min_child_weight': uniform(scale = 50),   #0 a 100\n",
    "          'colsample_bytree': uniform(0.65, 0.35), # Entre 0.75 y 1.\n",
    "          'n_estimators': list(range(500, 2500))    #ma que 500 tambein a la noche para que corra\n",
    "         }\n",
    "\n",
    "diccionario_auc_grid = {'g': None, 'auc': None}\n",
    "start = time.time()\n",
    "best_score = 0\n",
    "best_estimator = None\n",
    "iterations = 5\n",
    "for g in ParameterSampler(params, n_iter = iterations, random_state = random_state):\n",
    "    clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed = random_state, eval_metric = 'auc', **g, tree_method = 'gpu_hist') #enable_categorical = True\n",
    "    clf_xgb.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False)\n",
    "\n",
    "    y_pred = clf_xgb.predict_proba(X_val)[:, 1] # Obtenemos la probabilidad de una de las clases (cualquiera).\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "    \n",
    "    diccionario_auc_grid['auc'] = auc_roc\n",
    "    diccionario_auc_grid['g'] = g\n",
    "    print(f'Roc-AUC actual; {auc_roc}')\n",
    "    print(f'Con grid: {g}')\n",
    "    # Guardamos si es mejor.\n",
    "    if auc_roc > best_score:\n",
    "        print('-'*10)\n",
    "        print(f'Mejor valor de ROC-AUC encontrado: {auc_roc}')\n",
    "        print(f'Grid{g}')\n",
    "        print('-'*10)\n",
    "        best_score = auc_roc\n",
    "        best_grid = g\n",
    "        best_estimator = clf_xgb\n",
    "\n",
    "end = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.89185\n",
      "Grilla: {'colsample_bytree': 0.7242567734676637, 'gamma': 2.419044656729338, 'learning_rate': 0.01741128252899006, 'max_depth': 7, 'min_child_weight': 0.9726319911746439, 'n_estimators': 2432, 'reg_lambda': 1.85208462118521, 'subsample': 0.9196082041485403}\n",
      "Tiempo transcurrido: 162.50142192840576 segundos\n",
      "Tiempo de entrenamiento por iteración: 32.5 segundos\n"
     ]
    }
   ],
   "source": [
    "print('ROC-AUC: %0.5f' % best_score)\n",
    "print('Grilla:', best_grid)\n",
    "print(f'Tiempo transcurrido: {str(end - start)} segundos')\n",
    "print(f'Tiempo de entrenamiento por iteración: {str(round((end - start) / iterations, 2))} segundos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora con toda la data el prosible auc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC test: 0.89185\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_estimator.predict_proba(X_val)[:, 1]\n",
    "auc_roc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "print('AUC-ROC test: %0.5f' % auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entreno con toda la data train+val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed = random_state, eval_metric = 'auc', **best_grid,tree_method = 'gpu_hist') #enable_categorical = True\n",
    "clf_xgb.fit(X_train_all, y_train_all, verbose = False)\n",
    "final_model = clf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_submi = final_model.predict_proba(eval_data.drop(columns=[\"conversion\", \"ROW_ID\"]))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo el submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_preds = cls.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "# Make the submission file\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_pred_submi})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"basicOHE_XGB_GS_29.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
