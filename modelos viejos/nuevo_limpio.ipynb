{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# K Fold\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from statistics import mean, stdev\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy.stats import uniform\n",
    "import pandas as pd # Para cargar los datos y hacer OHE.\n",
    "import numpy as np  # Para lidiar con NaNs.\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#w2v\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import logging\n",
    "import gensim\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the competition data\n",
    "comp_data = pd.read_csv(\"../competition_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuneo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retoque de fecha - puedo ahcerlo antes porque son pocas y oredecibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data['date'] = pd.to_datetime(comp_data['date'])\n",
    "comp_data['month'] = comp_data['date'].dt.month\n",
    "# comp_data['day'] = comp_data['date'].dt.day\n",
    "comp_data['dayofweek'] = comp_data['date'].dt.dayofweek\n",
    "# comp_data['hour'] = comp_data['date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data['is_pdp'].fillna(-1, inplace=True)\n",
    "comp_data['is_pdp'] = comp_data['is_pdp'].replace({'True': 1, 'False': 0})\n",
    "comp_data['is_pdp'] = comp_data['is_pdp'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data['pdp_price'] = comp_data['is_pdp'] * comp_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PolynomialFeatures custom\n",
    "\n",
    "poly_attrs = [\"print_position\", \"offset\", \"price\", \"health\", \"original_price\"]\n",
    "\n",
    "for x in poly_attrs:\n",
    "    comp_data[x + \"2\"] = comp_data[x] ** 2\n",
    "\n",
    "for (x, y) in itertools.combinations(poly_attrs, 2):\n",
    "    comp_data[x + \"2 + \" + y + \"2\"] = comp_data[x] ** 2 + comp_data[y] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2Vec \n",
    "en title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = False\n",
    "if w2v:\n",
    "    # Descarga de stopwords para español si no están descargadas ya\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    STOP_WORDS_SP = set(stopwords.words('spanish'))\n",
    "\n",
    "    def iterate_LN_corpus(path):\n",
    "        \"\"\"\n",
    "        Genera un iterador para recorrer los archivos de texto en un directorio.\n",
    "\n",
    "        Args:\n",
    "            path (str): Ruta al directorio que contiene los archivos.\n",
    "\n",
    "        Yields:\n",
    "            str: Texto contenido en cada archivo.\n",
    "        \"\"\"\n",
    "        articles = os.listdir(path)\n",
    "        random.shuffle(articles)\n",
    "        for art in articles:\n",
    "            with open(path + art, encoding=\"utf-8\") as f:\n",
    "                raw_text = f.read()\n",
    "            yield(raw_text)\n",
    "\n",
    "    def tokenizer(raw_text):\n",
    "        \"\"\"\n",
    "        Tokeniza y preprocesa un texto.\n",
    "\n",
    "        Args:\n",
    "            raw_text (str): Texto sin procesar.\n",
    "\n",
    "        Returns:\n",
    "            list: Lista de oraciones, donde cada oración es una lista de palabras.\n",
    "        \"\"\"\n",
    "        sentences = sent_tokenize(raw_text)\n",
    "        sentences = [word_tokenize(e) for e in sentences]\n",
    "        sentences = [[e2 for e2 in e1 if re.compile(\"[A-Za-z]\").search(e2[0])] for e1 in sentences]\n",
    "        sentences = [[e2.lower() for e2 in e1] for e1 in sentences]\n",
    "        print(sentences)\n",
    "        return(sentences)\n",
    "\n",
    "    def gen_sentences(path):\n",
    "        \"\"\"\n",
    "        Genera una lista de oraciones a partir de archivos de texto en un directorio.\n",
    "\n",
    "        Args:\n",
    "            path (str): Ruta al directorio que contiene los archivos de texto.\n",
    "\n",
    "        Returns:\n",
    "            list: Lista de oraciones.\n",
    "        \"\"\"\n",
    "        sentences = []\n",
    "        n_arts = len(os.listdir(path))\n",
    "        for i, art in tqdm.tqdm(enumerate(iterate_LN_corpus(path)), total=n_arts):\n",
    "            sentences.extend(tokenizer(art))\n",
    "        return(sentences)\n",
    "\n",
    "    def average_vectors(title_tokens, model, stopwords=None):\n",
    "        \"\"\"\n",
    "        Calcula el vector promedio de un conjunto de tokens utilizando un modelo Word2Vec.\n",
    "\n",
    "        Args:\n",
    "            title_tokens (list): Lista de tokens.\n",
    "            model (gensim.models.Word2Vec): Modelo Word2Vec.\n",
    "            stopwords (set, optional): Conjunto de palabras stopwords. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Vector promedio.\n",
    "        \"\"\"\n",
    "        title_tokens = [e2 for e1 in title_tokens for e2 in e1]\n",
    "        title_tokens = [e for e in title_tokens if e in model.wv]\n",
    "        if stopwords is not None:\n",
    "            title_tokens = [e for e in title_tokens if e not in stopwords]\n",
    "        if len(title_tokens) == 0:\n",
    "            output = np.zeros(model.wv.vector_size)\n",
    "        else:\n",
    "            output = np.array([model.wv.get_vector(e) for e in title_tokens]).mean(0)\n",
    "        return output\n",
    "\n",
    "    def dummy_tokenizer(text_tokens):\n",
    "        \"\"\"\n",
    "        Tokenizador dummy que simplemente devuelve los tokens de texto sin procesar.\n",
    "\n",
    "        Args:\n",
    "            text_tokens (list): Lista de tokens.\n",
    "\n",
    "        Returns:\n",
    "            list: Misma lista de tokens de entrada.\n",
    "        \"\"\"\n",
    "        return text_tokens\n",
    "\n",
    "\n",
    "    #~ Análisis con datos de; TP ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # Carga de datos desde un archivo CSV\n",
    "    # comp_data = pd.read_csv(\"competition_data.csv\")\n",
    "    comp_data[\"title_tokens\"] = comp_data[\"title\"].map(tokenizer)\n",
    "\n",
    "    # Creación del modelo Word2Vec\n",
    "    w2v_tp = gensim.models.Word2Vec(vector_size= 300,     # Tamaño del vector\n",
    "                                    window=5,             # Tamaño de ventana\n",
    "                                    min_count=10,         # Frecuencia mínima de palabra\n",
    "                                    negative=20,          # Número de ejemplos negativos para muestreo negativo\n",
    "                                    sample=0.001,         # Submuestreo de palabras frecuentes\n",
    "                                    workers=8,            # Número de núcleos de CPU para entrenamiento paralelo\n",
    "                                    sg=1)                 # Algoritmo: 1 para Skip-gram, 0 para CBOW\n",
    "\n",
    "    # Creación del vocabulario a partir del corpus\n",
    "    w2v_tp.build_vocab([e2 for e1 in comp_data[\"title_tokens\"].values for e2 in e1],\n",
    "                    progress_per=10000)\n",
    "\n",
    "    # Entrenamiento del modelo Word2Vec\n",
    "    w2v_tp.train([e2 for e1 in comp_data[\"title_tokens\"].values for e2 in e1],\n",
    "                total_examples=w2v_tp.corpus_count,\n",
    "                epochs=30, report_delay=1)\n",
    "\n",
    "    ## Ejercicio de predicción con word2vec\n",
    "\n",
    "    # Obtención de embeddings de títulos utilizando el modelo Word2Vec\n",
    "    title_embs = comp_data[\"title_tokens\"].map(lambda x: average_vectors(x, w2v_tp, STOP_WORDS_SP))\n",
    "    title_embs= np.array(title_embs.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une compdata con los embs de los titulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if w2v:\n",
    "    title_embs_df = pd.DataFrame(title_embs, columns=[f\"emb_{i}\" for i in range(title_embs.shape[1])])\n",
    "\n",
    "    # Concatenate comp_data with title_embs_df along the columns axis (axis=1)\n",
    "    comp_data = pd.concat([comp_data, title_embs_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropeo \n",
    "atributos que no ayudan al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = comp_data.drop(\n",
    "    columns=['accepts_mercadopago', \n",
    "            # 'available_quantity',\n",
    "            # 'avg_gmv_item_domain_30days',\n",
    "            # 'avg_gmv_item_sel',\n",
    "            # 'avg_gmv_seller_bday',\n",
    "            # 'avg_qty_orders_item_domain_30days',\n",
    "            # 'avg_qty_orders_item_sel_30days',\n",
    "            # 'avg_si_item_sel_30day',\n",
    "            'benefit',              \n",
    "            'boosted',\n",
    "            'category_id',          \n",
    "            # 'conversion',\n",
    "            'date',             #chiche d efechas separar dia mes etc\n",
    "            'deal_print_id',\n",
    "            'domain_id',\n",
    "            'etl_version',\n",
    "            'free_shipping',    \n",
    "            'fulfillment',\n",
    "            'full_name',\n",
    "            # 'health',\n",
    "            # 'is_pdp',\n",
    "            'product_id',\n",
    "            'item_id',\n",
    "            # 'listing_type_id', #hacer OHE\n",
    "            # 'logistic_type',   #hacer OHE\n",
    "            'main_picture',\n",
    "            # 'offset',\n",
    "            # 'original_price',\n",
    "            # 'platform',        #hacer OHE\n",
    "            # 'price',\n",
    "            # 'print_position',\n",
    "            'print_server_timestamp',\n",
    "            # 'qty_items_dom',\n",
    "            # 'qty_items_sel',\n",
    "            'site_id',\n",
    "            # 'sold_quantity',\n",
    "            'tags',             #experimentar\n",
    "            'title',            #W2vec\n",
    "            # 'total_asp_item_domain_30days',\n",
    "            # 'total_asp_item_sel_30days',\n",
    "            # 'total_gmv_domain_bday',\n",
    "            # 'total_gmv_item_30days',\n",
    "            # 'total_items_domain',\n",
    "            # 'total_items_seller',\n",
    "            # 'total_orders_domain_30days',\n",
    "            # 'total_orders_item_30days',\n",
    "            # 'total_orders_sel_30days',\n",
    "            # 'total_si_domain_30days',\n",
    "            # 'total_si_item_30days',\n",
    "            # 'total_si_sel_30days',\n",
    "            # 'total_visits_domain',\n",
    "            # 'total_visits_item',\n",
    "            # 'total_visits_seller',\n",
    "            'uid',\n",
    "            'user_id',\n",
    "            'warranty',\n",
    "            # 'ROW_ID',\n",
    "            # 'title_tokens',\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "available_quantity                     int64\n",
       "avg_gmv_item_domain_30days           float64\n",
       "avg_gmv_item_sel                     float64\n",
       "avg_gmv_seller_bday                  float64\n",
       "avg_qty_orders_item_domain_30days    float64\n",
       "avg_qty_orders_item_sel_30days       float64\n",
       "avg_si_item_sel_30day                float64\n",
       "conversion                           float64\n",
       "health                               float64\n",
       "is_pdp                                 int32\n",
       "listing_type_id                       object\n",
       "logistic_type                         object\n",
       "offset                                 int64\n",
       "original_price                         int64\n",
       "platform                              object\n",
       "price                                  int64\n",
       "print_position                         int64\n",
       "qty_items_dom                        float64\n",
       "qty_items_sel                        float64\n",
       "sold_quantity                          int64\n",
       "total_asp_item_domain_30days         float64\n",
       "total_asp_item_sel_30days            float64\n",
       "total_gmv_domain_bday                float64\n",
       "total_gmv_item_30days                float64\n",
       "total_items_domain                     int64\n",
       "total_items_seller                     int64\n",
       "total_orders_domain_30days           float64\n",
       "total_orders_item_30days             float64\n",
       "total_orders_sel_30days              float64\n",
       "total_si_domain_30days               float64\n",
       "total_si_item_30days                 float64\n",
       "total_si_sel_30days                  float64\n",
       "total_visits_domain                    int64\n",
       "total_visits_item                      int64\n",
       "total_visits_seller                    int64\n",
       "ROW_ID                               float64\n",
       "month                                  int32\n",
       "dayofweek                              int32\n",
       "pdp_price                              int64\n",
       "print_position2                        int64\n",
       "offset2                                int64\n",
       "price2                                 int64\n",
       "health2                              float64\n",
       "original_price2                        int64\n",
       "print_position2 + offset2              int64\n",
       "print_position2 + price2               int64\n",
       "print_position2 + health2            float64\n",
       "print_position2 + original_price2      int64\n",
       "offset2 + price2                       int64\n",
       "offset2 + health2                    float64\n",
       "offset2 + original_price2              int64\n",
       "price2 + health2                     float64\n",
       "price2 + original_price2               int64\n",
       "health2 + original_price2            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set - HOLDOUT SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and evaluation samples\n",
    "train_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "del comp_data\n",
    "gc.collect()\n",
    "\n",
    "# train_data = pd.get_dummies(train_data, columns=['is_pdp','listing_type_id','logistic_type','platform','month','dayofweek'])\n",
    "y_train_all = train_data[\"conversion\"]\n",
    "X_train_all = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "del train_data\n",
    "gc.collect()\n",
    "\n",
    "#hold out set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=random_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE \n",
    "en las categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = pd.get_dummies(X_train, columns=['is_pdp','listing_type_id','logistic_type','platform','month','dayofweek']) \n",
    "\n",
    "X_val = pd.get_dummies(X_val, columns=['is_pdp','listing_type_id','logistic_type','platform','month','dayofweek']) \n",
    "\n",
    "eval_data = pd.get_dummies(eval_data, columns=['is_pdp','listing_type_id','logistic_type','platform','month','dayofweek'])\n",
    "\n",
    "X_train_all = pd.get_dummies(X_train_all, columns=['is_pdp','listing_type_id','logistic_type','platform','month','dayofweek'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# align X_train and eval_data\n",
    "eval_data_rowid = eval_data[\"ROW_ID\"]\n",
    "\n",
    "X_train_all, eval_data = X_train_all.align(eval_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Concatenar los DataFrames\n",
    "eval_data = pd.concat([eval_data, eval_data_rowid], axis=1)\n",
    "\n",
    "# Ahora eval_data contiene las columnas de eval_data, eval_data_conversion y eval_data_rowid concatenadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('int64') dtype('float64') dtype('bool')]\n"
     ]
    }
   ],
   "source": [
    "# X_train_all.dtypes\n",
    "unique_data_types = X_train_all.dtypes.unique()\n",
    "print(unique_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19211, 72)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de aprendizaje - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc-AUC actual; 0.8804430075529042\n",
      "Con grid: {'colsample_bytree': 0.7810890415965769, 'gamma': 14.260714596148743, 'learning_rate': 0.02195981825434215, 'max_depth': 7, 'min_child_weight': 7.800932022121826, 'n_estimators': 966, 'reg_lambda': 1.4996237372700434, 'subsample': 0.7296244459829335}\n",
      "----------\n",
      "Mejor valor de ROC-AUC encontrado: 0.8804430075529042\n",
      "Grid{'colsample_bytree': 0.7810890415965769, 'gamma': 14.260714596148743, 'learning_rate': 0.02195981825434215, 'max_depth': 7, 'min_child_weight': 7.800932022121826, 'n_estimators': 966, 'reg_lambda': 1.4996237372700434, 'subsample': 0.7296244459829335}\n",
      "----------\n",
      "Roc-AUC actual; 0.8914379432866186\n",
      "Con grid: {'colsample_bytree': 0.7667980138986576, 'gamma': 2.143002268829112, 'learning_rate': 0.019526654188465584, 'max_depth': 7, 'min_child_weight': 48.49549260809972, 'n_estimators': 2015, 'reg_lambda': 14.078290635236252, 'subsample': 0.5003893829205072}\n",
      "----------\n",
      "Mejor valor de ROC-AUC encontrado: 0.8914379432866186\n",
      "Grid{'colsample_bytree': 0.7667980138986576, 'gamma': 2.143002268829112, 'learning_rate': 0.019526654188465584, 'max_depth': 7, 'min_child_weight': 48.49549260809972, 'n_estimators': 2015, 'reg_lambda': 14.078290635236252, 'subsample': 0.5003893829205072}\n",
      "----------\n",
      "Roc-AUC actual; 0.8846830887668584\n",
      "Con grid: {'colsample_bytree': 0.9972740457519261, 'gamma': 9.262222644415749, 'learning_rate': 0.018349594814648425, 'max_depth': 11, 'min_child_weight': 14.561457009902096, 'n_estimators': 1582, 'reg_lambda': 5.997914575728832, 'subsample': 0.5233328316068078}\n",
      "Roc-AUC actual; 0.8768777705316317\n",
      "Con grid: {'colsample_bytree': 0.9908144315945107, 'gamma': 3.4915701064545637, 'learning_rate': 0.002718193035984624, 'max_depth': 5, 'min_child_weight': 19.12309956335814, 'n_estimators': 1767, 'reg_lambda': 8.886218532930638, 'subsample': 0.5232252063599989}\n",
      "Roc-AUC actual; 0.8700409896856849\n",
      "Con grid: {'colsample_bytree': 0.8626406981655035, 'gamma': 2.557861855309373, 'learning_rate': 0.0019515477895583853, 'max_depth': 6, 'min_child_weight': 47.11008778424264, 'n_estimators': 513, 'reg_lambda': 12.125960221746917, 'subsample': 0.6523068845866853}\n",
      "Roc-AUC actual; 0.8827597914954083\n",
      "Con grid: {'colsample_bytree': 0.6841852399022343, 'gamma': 10.263495397682354, 'learning_rate': 0.01320457481218804, 'max_depth': 9, 'min_child_weight': 30.499832889131046, 'n_estimators': 1275, 'reg_lambda': 0.5158278167282759, 'subsample': 0.954660201039391}\n",
      "Roc-AUC actual; 0.8824328916586148\n",
      "Con grid: {'colsample_bytree': 0.7405729935600059, 'gamma': 9.93783426530973, 'learning_rate': 0.009351332282682328, 'max_depth': 8, 'min_child_weight': 10.397083143409441, 'n_estimators': 2295, 'reg_lambda': 2.7728168328829055, 'subsample': 0.9847923138822793}\n",
      "Roc-AUC actual; 0.8813424616022746\n",
      "Con grid: {'colsample_bytree': 0.9212964881763901, 'gamma': 14.092484123462837, 'learning_rate': 0.026844820512829465, 'max_depth': 10, 'min_child_weight': 28.52219872026997, 'n_estimators': 1775, 'reg_lambda': 0.678409333658071, 'subsample': 0.6626651653816322}\n",
      "Roc-AUC actual; 0.8914849897353123\n",
      "Con grid: {'colsample_bytree': 0.7860370513913187, 'gamma': 4.070235476608438, 'learning_rate': 0.02486212527455788, 'max_depth': 11, 'min_child_weight': 14.046725484369038, 'n_estimators': 879, 'reg_lambda': 4.1399877303381505, 'subsample': 0.6481367528520412}\n",
      "----------\n",
      "Mejor valor de ROC-AUC encontrado: 0.8914849897353123\n",
      "Grid{'colsample_bytree': 0.7860370513913187, 'gamma': 4.070235476608438, 'learning_rate': 0.02486212527455788, 'max_depth': 11, 'min_child_weight': 14.046725484369038, 'n_estimators': 879, 'reg_lambda': 4.1399877303381505, 'subsample': 0.6481367528520412}\n",
      "----------\n",
      "Roc-AUC actual; 0.8842350661301651\n",
      "Con grid: {'colsample_bytree': 0.7078434286720509, 'gamma': 0.23454610111790897, 'learning_rate': 0.012702044421191088, 'max_depth': 3, 'min_child_weight': 9.93578407670862, 'n_estimators': 1995, 'reg_lambda': 0.21119734072626684, 'subsample': 0.5994212020444025}\n",
      "Roc-AUC actual; 0.8816358121412342\n",
      "Con grid: {'colsample_bytree': 0.8989696834620275, 'gamma': 11.852633107968085, 'learning_rate': 0.01817879924343034, 'max_depth': 9, 'min_child_weight': 32.55385127509722, 'n_estimators': 1551, 'reg_lambda': 12.946551388133903, 'subsample': 0.811649063413779}\n",
      "Roc-AUC actual; 0.8906878479165428\n",
      "Con grid: {'colsample_bytree': 0.7658143086984273, 'gamma': 0.9533752542903545, 'learning_rate': 0.009329469651469866, 'max_depth': 10, 'min_child_weight': 33.296117830874834, 'n_estimators': 1183, 'reg_lambda': 9.563362070328196, 'subsample': 0.9436063712881633}\n",
      "Roc-AUC actual; 0.8822908756429926\n",
      "Con grid: {'colsample_bytree': 0.8152752238066823, 'gamma': 1.7939136890745255, 'learning_rate': 0.021397343616689848, 'max_depth': 3, 'min_child_weight': 36.08647605824366, 'n_estimators': 1002, 'reg_lambda': 11.564507699318415, 'subsample': 0.7468977981821954}\n",
      "Roc-AUC actual; 0.8687367902142961\n",
      "Con grid: {'colsample_bytree': 0.8329564902836979, 'gamma': 6.413115275378244, 'learning_rate': 0.0007625738023228556, 'max_depth': 5, 'min_child_weight': 1.5714592843367126, 'n_estimators': 1242, 'reg_lambda': 7.130553347731676, 'subsample': 0.7816377859881918}\n",
      "Roc-AUC actual; 0.8911432488177022\n",
      "Con grid: {'colsample_bytree': 0.8934306302491446, 'gamma': 2.089971816088135, 'learning_rate': 0.018132521378334515, 'max_depth': 6, 'min_child_weight': 47.14267852789905, 'n_estimators': 2362, 'reg_lambda': 4.346271793706521, 'subsample': 0.5806106436270022}\n",
      "Roc-AUC actual; 0.8817080150006792\n",
      "Con grid: {'colsample_bytree': 0.9753941783199005, 'gamma': 12.121805693466253, 'learning_rate': 0.019002112695312705, 'max_depth': 8, 'min_child_weight': 22.826728524145512, 'n_estimators': 2143, 'reg_lambda': 2.7985508832905377, 'subsample': 0.9462794992449889}\n",
      "Roc-AUC actual; 0.882050160877316\n",
      "Con grid: {'colsample_bytree': 0.8387697846704778, 'gamma': 12.111602327460938, 'learning_rate': 0.026882738997704797, 'max_depth': 9, 'min_child_weight': 45.3414220772877, 'n_estimators': 1908, 'reg_lambda': 3.4190274381291252, 'subsample': 0.7135538943131281}\n",
      "Roc-AUC actual; 0.86937423577334\n",
      "Con grid: {'colsample_bytree': 0.9363051680728727, 'gamma': 12.910958748845152, 'learning_rate': 0.00020856391593572108, 'max_depth': 10, 'min_child_weight': 26.7044709687721, 'n_estimators': 817, 'reg_lambda': 3.3316171570609536, 'subsample': 0.5599326836668415}\n",
      "Roc-AUC actual; 0.8802523742035725\n",
      "Con grid: {'colsample_bytree': 0.7681653099912698, 'gamma': 14.143645558687787, 'learning_rate': 0.009696087960622657, 'max_depth': 10, 'min_child_weight': 35.15094794475889, 'n_estimators': 1636, 'reg_lambda': 0.9733837066347234, 'subsample': 0.6269577069671723}\n",
      "Roc-AUC actual; 0.8811289992440705\n",
      "Con grid: {'colsample_bytree': 0.7364066219935105, 'gamma': 10.444564092596826, 'learning_rate': 0.02136811769773326, 'max_depth': 7, 'min_child_weight': 14.242024718873381, 'n_estimators': 1604, 'reg_lambda': 4.001715214129275, 'subsample': 0.9883074779163264}\n",
      "Roc-AUC actual; 0.8811823514833239\n",
      "Con grid: {'colsample_bytree': 0.7938629546613809, 'gamma': 0.4957609935082258, 'learning_rate': 0.010352137440800489, 'max_depth': 3, 'min_child_weight': 11.97809453334862, 'n_estimators': 1653, 'reg_lambda': 7.964018749757046, 'subsample': 0.7238915822865458}\n",
      "Roc-AUC actual; 0.878186856211937\n",
      "Con grid: {'colsample_bytree': 0.8435125811749649, 'gamma': 8.890450858190903, 'learning_rate': 0.0024255997899814575, 'max_depth': 10, 'min_child_weight': 11.881877199619984, 'n_estimators': 1266, 'reg_lambda': 12.047096345698439, 'subsample': 0.7351503172230192}\n",
      "Roc-AUC actual; 0.8810775605474712\n",
      "Con grid: {'colsample_bytree': 0.994198099313195, 'gamma': 5.982366636668296, 'learning_rate': 0.024492956196581518, 'max_depth': 3, 'min_child_weight': 7.535877198271473, 'n_estimators': 686, 'reg_lambda': 2.7977776559978134, 'subsample': 0.520387570777382}\n",
      "Roc-AUC actual; 0.8684953990335418\n",
      "Con grid: {'colsample_bytree': 0.8568125301158847, 'gamma': 10.163465427634236, 'learning_rate': 0.0004976348678356846, 'max_depth': 5, 'min_child_weight': 40.47505230698577, 'n_estimators': 1671, 'reg_lambda': 9.677591856141747, 'subsample': 0.5871832145024958}\n",
      "Roc-AUC actual; 0.8818173405876121\n",
      "Con grid: {'colsample_bytree': 0.8918282083358631, 'gamma': 5.801030194508061, 'learning_rate': 0.028101899662102036, 'max_depth': 3, 'min_child_weight': 33.784505851964035, 'n_estimators': 2476, 'reg_lambda': 1.702102818608836, 'subsample': 0.9623468091392814}\n",
      "Roc-AUC actual; 0.8922264029618578\n",
      "Con grid: {'colsample_bytree': 0.9570687736833434, 'gamma': 3.869124415727334, 'learning_rate': 0.01979952138102537, 'max_depth': 11, 'min_child_weight': 25.831794563550716, 'n_estimators': 1380, 'reg_lambda': 3.627784363506775, 'subsample': 0.5465513839029497}\n",
      "----------\n",
      "Mejor valor de ROC-AUC encontrado: 0.8922264029618578\n",
      "Grid{'colsample_bytree': 0.9570687736833434, 'gamma': 3.869124415727334, 'learning_rate': 0.01979952138102537, 'max_depth': 11, 'min_child_weight': 25.831794563550716, 'n_estimators': 1380, 'reg_lambda': 3.627784363506775, 'subsample': 0.5465513839029497}\n",
      "----------\n",
      "Roc-AUC actual; 0.8804906147140964\n",
      "Con grid: {'colsample_bytree': 0.9640255152836643, 'gamma': 13.506270857449957, 'learning_rate': 0.018993043718198037, 'max_depth': 11, 'min_child_weight': 13.943567629609094, 'n_estimators': 2182, 'reg_lambda': 10.889335183053591, 'subsample': 0.9485551299762885}\n",
      "Roc-AUC actual; 0.8796762821621351\n",
      "Con grid: {'colsample_bytree': 0.960480248492791, 'gamma': 11.698133187864357, 'learning_rate': 0.01926094938462863, 'max_depth': 3, 'min_child_weight': 8.081435704730689, 'n_estimators': 1945, 'reg_lambda': 10.034823820713429, 'subsample': 0.7903433107182274}\n",
      "Roc-AUC actual; 0.878930280883319\n",
      "Con grid: {'colsample_bytree': 0.7802989682966102, 'gamma': 14.102001636866676, 'learning_rate': 0.02920991510265952, 'max_depth': 4, 'min_child_weight': 8.040402570874933, 'n_estimators': 837, 'reg_lambda': 7.284206303793399, 'subsample': 0.7242120714931237}\n",
      "Roc-AUC actual; 0.8718264317842602\n",
      "Con grid: {'colsample_bytree': 0.9980601119137873, 'gamma': 2.638878790160181, 'learning_rate': 0.000542260908465626, 'max_depth': 7, 'min_child_weight': 8.941135461066441, 'n_estimators': 2027, 'reg_lambda': 9.74449348570822, 'subsample': 0.924611705247089}\n",
      "Roc-AUC actual; 0.8752536356286903\n",
      "Con grid: {'colsample_bytree': 0.8801645123051202, 'gamma': 8.524629050032074, 'learning_rate': 0.002810243034842774, 'max_depth': 5, 'min_child_weight': 31.81663090929477, 'n_estimators': 1545, 'reg_lambda': 3.659844650686254, 'subsample': 0.9865052773762228}\n",
      "Roc-AUC actual; 0.8795106806207775\n",
      "Con grid: {'colsample_bytree': 0.7875842036333661, 'gamma': 13.380698327656699, 'learning_rate': 0.018934158779917887, 'max_depth': 4, 'min_child_weight': 17.503920384733785, 'n_estimators': 2132, 'reg_lambda': 8.653558269395386, 'subsample': 0.746258846909432}\n",
      "Roc-AUC actual; 0.8794308013402203\n",
      "Con grid: {'colsample_bytree': 0.7183350457293156, 'gamma': 10.83678172892258, 'learning_rate': 0.008423170873225673, 'max_depth': 5, 'min_child_weight': 38.42770071531545, 'n_estimators': 2035, 'reg_lambda': 2.6566601911057344, 'subsample': 0.9702292921764571}\n",
      "Roc-AUC actual; 0.8803982751557922\n",
      "Con grid: {'colsample_bytree': 0.9838750019509056, 'gamma': 13.722965853306729, 'learning_rate': 0.011104761007663331, 'max_depth': 11, 'min_child_weight': 47.65359235119766, 'n_estimators': 1872, 'reg_lambda': 6.422762224759715, 'subsample': 0.9833274095218347}\n",
      "Roc-AUC actual; 0.8807947567436046\n",
      "Con grid: {'colsample_bytree': 0.9872669919812385, 'gamma': 12.795141832010401, 'learning_rate': 0.00883346676208757, 'max_depth': 7, 'min_child_weight': 9.545551557517301, 'n_estimators': 1684, 'reg_lambda': 4.753830077344165, 'subsample': 0.5847463733430462}\n",
      "Roc-AUC actual; 0.8799610351094492\n",
      "Con grid: {'colsample_bytree': 0.8448804418604225, 'gamma': 14.042321612411715, 'learning_rate': 0.02088089390024919, 'max_depth': 10, 'min_child_weight': 3.520806542477195, 'n_estimators': 1125, 'reg_lambda': 9.225108400487546, 'subsample': 0.9950269250521316}\n",
      "Roc-AUC actual; 0.882710951656739\n",
      "Con grid: {'colsample_bytree': 0.6990294053327835, 'gamma': 7.774944785456051, 'learning_rate': 0.026321192157838662, 'max_depth': 3, 'min_child_weight': 42.43348974623372, 'n_estimators': 1916, 'reg_lambda': 10.53726125980664, 'subsample': 0.6797455756098776}\n",
      "Roc-AUC actual; 0.8816649691911623\n",
      "Con grid: {'colsample_bytree': 0.7527571454925727, 'gamma': 12.140417332177705, 'learning_rate': 0.02430340184037542, 'max_depth': 11, 'min_child_weight': 30.575685543284024, 'n_estimators': 1327, 'reg_lambda': 7.670135982914067, 'subsample': 0.7507581473435998}\n",
      "Roc-AUC actual; 0.8823829214947498\n",
      "Con grid: {'colsample_bytree': 0.9294033126383713, 'gamma': 9.749458961666477, 'learning_rate': 0.0210590063177311, 'max_depth': 5, 'min_child_weight': 16.89975784257679, 'n_estimators': 1615, 'reg_lambda': 8.68297343261338, 'subsample': 0.7192370615090435}\n",
      "Roc-AUC actual; 0.8871469840885635\n",
      "Con grid: {'colsample_bytree': 0.8852091473533198, 'gamma': 4.922290012120979, 'learning_rate': 0.004651248501832326, 'max_depth': 8, 'min_child_weight': 29.541663028450536, 'n_estimators': 1865, 'reg_lambda': 3.753770407737961, 'subsample': 0.5194173672147115}\n",
      "Roc-AUC actual; 0.8843181361318453\n",
      "Con grid: {'colsample_bytree': 0.7561429301356279, 'gamma': 8.056236407949832, 'learning_rate': 0.009799537253881226, 'max_depth': 10, 'min_child_weight': 38.499677654930544, 'n_estimators': 1503, 'reg_lambda': 14.478777455861547, 'subsample': 0.7286325808068643}\n",
      "Roc-AUC actual; 0.8857618106122157\n",
      "Con grid: {'colsample_bytree': 0.9447080762541935, 'gamma': 2.9157005099230955, 'learning_rate': 0.012340617151700357, 'max_depth': 5, 'min_child_weight': 31.871495074910328, 'n_estimators': 2343, 'reg_lambda': 1.9911813336445472, 'subsample': 0.9847684335570794}\n",
      "Roc-AUC actual; 0.8900206000431873\n",
      "Con grid: {'colsample_bytree': 0.9001082864629832, 'gamma': 0.6160127515181368, 'learning_rate': 0.011964627043343836, 'max_depth': 5, 'min_child_weight': 21.948571035281805, 'n_estimators': 2474, 'reg_lambda': 3.762907910199918, 'subsample': 0.592166837165685}\n",
      "Roc-AUC actual; 0.8822710059500852\n",
      "Con grid: {'colsample_bytree': 0.6783055383160193, 'gamma': 6.424717124101616, 'learning_rate': 0.020654997022960992, 'max_depth': 3, 'min_child_weight': 8.664716003542289, 'n_estimators': 1012, 'reg_lambda': 6.635283445966566, 'subsample': 0.6198936795787016}\n",
      "Roc-AUC actual; 0.8846708732445673\n",
      "Con grid: {'colsample_bytree': 0.6828556515284522, 'gamma': 2.74298995660961, 'learning_rate': 0.02803841992019129, 'max_depth': 3, 'min_child_weight': 47.743264033159704, 'n_estimators': 1203, 'reg_lambda': 8.31531078767101, 'subsample': 0.8058603731171761}\n",
      "Roc-AUC actual; 0.892064259147575\n",
      "Con grid: {'colsample_bytree': 0.7968600218497265, 'gamma': 3.715964842517362, 'learning_rate': 0.010679180359537847, 'max_depth': 7, 'min_child_weight': 6.008232390282108, 'n_estimators': 1808, 'reg_lambda': 1.7410896076037434, 'subsample': 0.5230013210108764}\n",
      "Roc-AUC actual; 0.880654685421331\n",
      "Con grid: {'colsample_bytree': 0.6642550808116395, 'gamma': 12.831908760165108, 'learning_rate': 0.02110973578140071, 'max_depth': 7, 'min_child_weight': 23.673588539028284, 'n_estimators': 1812, 'reg_lambda': 6.9701071940941715, 'subsample': 0.8248868413213817}\n",
      "Roc-AUC actual; 0.8794891866416636\n",
      "Con grid: {'colsample_bytree': 0.6668206234689619, 'gamma': 14.237185973870789, 'learning_rate': 0.026600411618941427, 'max_depth': 6, 'min_child_weight': 18.73063073132356, 'n_estimators': 1261, 'reg_lambda': 14.001544621192245, 'subsample': 0.7505199419576296}\n",
      "Roc-AUC actual; 0.8822614382368152\n",
      "Con grid: {'colsample_bytree': 0.8387821069400219, 'gamma': 10.259456540972117, 'learning_rate': 0.018475534931697415, 'max_depth': 9, 'min_child_weight': 47.212579856258365, 'n_estimators': 1395, 'reg_lambda': 9.54605396169017, 'subsample': 0.9004746473411999}\n",
      "Roc-AUC actual; 0.878782003578129\n",
      "Con grid: {'colsample_bytree': 0.8870089198340436, 'gamma': 8.600505625079, 'learning_rate': 0.0038550105970173052, 'max_depth': 5, 'min_child_weight': 41.03197378719777, 'n_estimators': 1791, 'reg_lambda': 5.791539567011614, 'subsample': 0.9805952819119571}\n"
     ]
    }
   ],
   "source": [
    "#ver uan forma de tener mejor parametos que gerar\n",
    "params = {'max_depth': list(range(3, 12)),\n",
    "          'learning_rate': uniform(scale = 0.03),\n",
    "          'gamma': uniform(scale=15),               #chiche va de 1 a 20\n",
    "          'reg_lambda': uniform(scale = 15),        # Parámetro de regularización.\n",
    "          'subsample': uniform(0.5, 0.5),          # Entre 0.5 y 1.\n",
    "          'min_child_weight': uniform(scale = 50),   #0 a 100\n",
    "          'colsample_bytree': uniform(0.65, 0.35), # Entre 0.75 y 1.\n",
    "          'n_estimators': list(range(500, 2500))    #ma que 500 tambein a la noche para que corra\n",
    "         }\n",
    "\n",
    "l_auc = []\n",
    "l_grid = []\n",
    "start = time.time()\n",
    "random_state = 42\n",
    "best_score = 0\n",
    "best_estimator = None\n",
    "iterations = 250\n",
    "for g in ParameterSampler(params, n_iter = iterations, random_state = random_state):\n",
    "    clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed = random_state, eval_metric = 'auc', **g, tree_method = 'gpu_hist') #enable_categorical = True\n",
    "    clf_xgb.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False)\n",
    "\n",
    "    y_pred = clf_xgb.predict_proba(X_val)[:, 1] # Obtenemos la probabilidad de una de las clases (cualquiera).\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "    \n",
    "    l_auc.append(auc_roc)\n",
    "    l_grid.append(g)\n",
    "    print(f'Roc-AUC actual; {auc_roc}')\n",
    "    print(f'Con grid: {g}')\n",
    "    # Guardamos si es mejor.\n",
    "    if auc_roc > best_score:\n",
    "        print('-'*10)\n",
    "        print(f'Mejor valor de ROC-AUC encontrado: {auc_roc}')\n",
    "        print(f'Grid{g}')\n",
    "        print('-'*10)\n",
    "        best_score = auc_roc\n",
    "        best_grid = g\n",
    "        best_estimator = clf_xgb\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "df_aux = pd.DataFrame({'auc': l_auc, 'grid': l_grid})\n",
    "df_aux.to_csv('grid_search.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "me quedo con el mejor auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.89223\n",
      "Grilla: {'colsample_bytree': 0.9570687736833434, 'gamma': 3.869124415727334, 'learning_rate': 0.01979952138102537, 'max_depth': 11, 'min_child_weight': 25.831794563550716, 'n_estimators': 1380, 'reg_lambda': 3.627784363506775, 'subsample': 0.5465513839029497}\n",
      "Tiempo transcurrido: 1380.2295110225677 segundos\n",
      "Tiempo de entrenamiento por iteración: 27.6 segundos\n"
     ]
    }
   ],
   "source": [
    "print('ROC-AUC: %0.5f' % best_score)\n",
    "print('Grilla:', best_grid)\n",
    "print(f'Tiempo transcurrido: {str(end - start)} segundos')\n",
    "print(f'Tiempo de entrenamiento por iteración: {str(round((end - start) / iterations, 2))} segundos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora con toda la data el prosible auc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC test: 0.89223\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_estimator.predict_proba(X_val)[:, 1]\n",
    "auc_roc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "print('AUC-ROC test: %0.5f' % auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entreno con toda la data train+val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_grid = {'colsample_bytree': 0.7860370513913187, 'gamma': 4.070235476608438, 'learning_rate': 0.02486212527455788, 'max_depth': 11, 'min_child_weight': 14.046725484369038, 'n_estimators': 879, 'reg_lambda': 4.1399877303381505, 'subsample': 0.6481367528520412}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed = random_state, eval_metric = 'auc', **best_grid,tree_method = 'gpu_hist') #enable_categorical = True\n",
    "clf_xgb.fit(X_train_all, y_train_all, verbose = False)\n",
    "final_model = clf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submit = final_model.predict_proba(eval_data.drop(columns=[ \"ROW_ID\"]))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_preds = cls.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "# Make the submission file\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_pred_submit})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"noche_250.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
