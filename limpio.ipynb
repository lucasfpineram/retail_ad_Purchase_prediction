{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd # Para cargar los datos y hacer OHE.\n",
    "import numpy as np  # Para lidiar con NaNs.\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7907696632911395\n",
      "{'colsample_bytree': 0.9151610773058515, 'gamma': 0.827201304042807, 'learning_rate': 0.10021538369719958, 'max_depth': 14, 'min_child_weight': 3.4391200843333576, 'n_estimators': 123, 'reg_lambda': 3.184092322548138, 'subsample': 0.58609692603256}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "params = {'max_depth': list(range(1, 20)),\n",
    "          'learning_rate': uniform(scale = 0.15),\n",
    "          'gamma': uniform(scale = 2),\n",
    "          'reg_lambda': uniform(scale = 5),        # Parámetro de regularización.\n",
    "          'subsample': uniform(0.5, 0.5),          # Entre 0.5 y 1.\n",
    "          'min_child_weight': uniform(scale = 5),\n",
    "          'colsample_bytree': uniform(0.75, 0.25), # Entre 0.75 y 1.\n",
    "          'n_estimators': list(range(1, 300))\n",
    "         }\n",
    "\n",
    "# Load the competition data\n",
    "comp_data = pd.read_csv(\"./competition_data.csv\")\n",
    "\n",
    "\n",
    "# Split into training and evaluation samples\n",
    "train_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "del comp_data\n",
    "gc.collect()\n",
    "\n",
    "y_train = train_data[\"conversion\"]\n",
    "X_train = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "X_train = X_train.select_dtypes(include='number') ## retoque de datos para que haya mas\n",
    "del train_data\n",
    "gc.collect()\n",
    "\n",
    "#hold out set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=3456)\n",
    "\n",
    "# # Train a random forest model on the train data\n",
    "# train_data = train_data.sample(frac=1/3)\n",
    "# y_train = train_data[\"conversion\"]\n",
    "# X_train = train_data.drop(columns=[\"conversion\", \"ROW_ID\"])\n",
    "# X_train = X_train.select_dtypes(include='number')\n",
    "# del train_data\n",
    "# gc.collect()\n",
    "start = time.time()–\n",
    "best_score = 0\n",
    "best_estimator = None\n",
    "iterations = 1\n",
    "y_preds_list = []\n",
    "for g in ParameterSampler(params, n_iter = iterations, random_state = 2345):\n",
    "    cls = xgb.XGBClassifier(objective = 'binary:logistic', seed = 2345, eval_metric = 'auc', **g)\n",
    "    # cls.fit(X_train + X_val, y_train)\n",
    "    cls.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the evaluation set\n",
    "    # y_preds = cls.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "    y_preds = cls.predict_proba(X_val)[:, 1] \n",
    "    y_preds_list.append(y_preds)\n",
    "\n",
    "    print(roc_auc_score(y_val,y_preds))\n",
    "    print(g)\n",
    "    y_preds = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36153,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_preds_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 36153 does not match index length 19211",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/valen/Desktop/Ditella/Año 3 sem 2/TD6/tp2_td6/limpio.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valen/Desktop/Ditella/A%C3%B1o%203%20sem%202/TD6/tp2_td6/limpio.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# y_preds = cls.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valen/Desktop/Ditella/A%C3%B1o%203%20sem%202/TD6/tp2_td6/limpio.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Make the submission file\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/valen/Desktop/Ditella/A%C3%B1o%203%20sem%202/TD6/tp2_td6/limpio.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m submission_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m\"\u001b[39;49m\u001b[39mROW_ID\u001b[39;49m\u001b[39m\"\u001b[39;49m: eval_data[\u001b[39m\"\u001b[39;49m\u001b[39mROW_ID\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mconversion\u001b[39;49m\u001b[39m\"\u001b[39;49m: y_preds})\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valen/Desktop/Ditella/A%C3%B1o%203%20sem%202/TD6/tp2_td6/limpio.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m submission_df[\u001b[39m\"\u001b[39m\u001b[39mROW_ID\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m submission_df[\u001b[39m\"\u001b[39m\u001b[39mROW_ID\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valen/Desktop/Ditella/A%C3%B1o%203%20sem%202/TD6/tp2_td6/limpio.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m submission_df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mbasic_model_xgboostoro.csv\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    637\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    121\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:688\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[39mif\u001b[39;00m lengths[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m    684\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    685\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marray length \u001b[39m\u001b[39m{\u001b[39;00mlengths[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m does not match index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlength \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    687\u001b[0m         )\n\u001b[0;32m--> 688\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     index \u001b[39m=\u001b[39m default_index(lengths[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 36153 does not match index length 19211"
     ]
    }
   ],
   "source": [
    "# y_preds = cls.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "# Make the submission file\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"basic_model_xgboostoro.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
